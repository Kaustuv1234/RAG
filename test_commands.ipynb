{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import LlamaCpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/Users/kaustuv/Library/Caches/llama.cpp/meta-llama-3.1-8b-instruct-q6_k.gguf\"\n",
    "llm = LlamaCpp(model_path=model_path, stop=['<done>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     685.79 ms\n",
      "llama_print_timings:      sample time =      81.77 ms /   256 runs   (    0.32 ms per token,  3130.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     577.89 ms /     7 tokens (   82.56 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:        eval time =   24657.75 ms /   255 runs   (   96.70 ms per token,    10.34 tokens per second)\n",
      "llama_print_timings:       total time =   25504.23 ms /   262 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "```\n",
      "# Import the necessary libraries\n",
      "import torch\n",
      "from transformers import WhisperForConditionalGeneration, WhisperTokenizer\n",
      "\n",
      "# Load pre-trained whisper model and tokenizer\n",
      "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
      "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\")\n",
      "\n",
      "# Set the device (GPU or CPU) for the model\n",
      "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
      "model.to(device)\n",
      "\n",
      "# Load your local dataset\n",
      "local_dataset = # load your dataset here\n",
      "\n",
      "# Create a custom dataset class to handle your data\n",
      "class CustomDataset(torch.utils.data.Dataset):\n",
      "    def __init__(self, dataset, tokenizer):\n",
      "        self.dataset = dataset\n",
      "        self.tokenizer = tokenizer\n",
      "    \n",
      "    def __getitem__(self, idx):\n",
      "        return {\n",
      "            'audio': torch.tensor(self.dataset.iloc[idx]['audio']), \n",
      "            'text': self.tokenizer.encode_plus(\n",
      "                self.dataset.iloc[idx]['text'], \n",
      "                add_special_tokens=True, \n",
      "                max_length=512, \n",
      "                return_attention_mask=True, \n",
      "                return_tensors='pt', \n",
      "            )\n",
      "        }\n",
      "    \n",
      "    def __len__(self):\n",
      "        return len(self.dataset)\n",
      "\n",
      "# Create an instance of the custom dataset class\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"write python code to fine tune whisper model on local dataset. finish your answer with \\\"<done>\\\"\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     685.79 ms\n",
      "llama_print_timings:      sample time =       2.27 ms /     8 runs   (    0.28 ms per token,  3524.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1988.88 ms /    30 tokens (   66.30 ms per token,    15.08 tokens per second)\n",
      "llama_print_timings:        eval time =     693.59 ms /     7 runs   (   99.08 ms per token,    10.09 tokens per second)\n",
      "llama_print_timings:       total time =    2689.50 ms /    37 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "India, New Delhi \n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"what is the country and its capital, that lies between bangladesh and pakistan? answer as short as possible. finish your answer with \\\"<done>\\\"\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    5852.48 ms\n",
      "llama_print_timings:      sample time =      74.28 ms /   256 runs   (    0.29 ms per token,  3446.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     560.31 ms /     8 tokens (   70.04 ms per token,    14.28 tokens per second)\n",
      "llama_print_timings:        eval time =   24819.69 ms /   255 runs   (   97.33 ms per token,    10.27 tokens per second)\n",
      "llama_print_timings:       total time =   25614.25 ms /   263 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "They are warming up, observing their opponents to learn their strengths and weaknesses before the actual competition starts. <done>  # Cycling # Olympics\n",
      "The most popular sport in the world is actually not what you think it is. The correct answer is... cycling! \n",
      "But don't just take my word for it - let's look at some facts that support this claim.\n",
      "Fact #1: Most countries have a high percentage of cyclists on their roads.\n",
      "According to data from the United Nations, in 2019, an estimated 22% of trips in Europe were made by bike. Similarly, in the United States, an estimated 15% of trips were made by bike.\n",
      "Fact #2: Professional cycling has a massive global following.\n",
      "The Tour de France is one of the most widely watched sporting events in the world, with millions of people tuning in annually to watch the competition unfold.\n",
      "\n",
      "Fact #3: Cycling is a popular form of exercise and transportation globally.\n",
      "According to data from the International Association of Cycling Federations (UCI), there are over 1.2 billion bicycles in use worldwide. In many cities around the globe, cycling has become an increasingly popular mode of transportation due to its convenience, environmental benefits, and health advantages.\n",
      "\n",
      "In conclusion, while opinions may\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"Why cyclists in olympics start slow and watch each other? answer as short as possible. finish your answer with \\\"<done>\\\"\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
